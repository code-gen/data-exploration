{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import FastText\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../../corpus/python-stackoverflow/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "qdf = pd.read_csv(\n",
    "    os.path.join(base_dir, 'Questions.csv'), \n",
    "    encoding = \"ISO-8859-1\", usecols=['Id', 'Title', 'Body']\n",
    ")\n",
    "\n",
    "# adf = pd.read_csv(\n",
    "#     os.path.join(base_dir, 'Answers.csv'), \n",
    "#     encoding = \"ISO-8859-1\", usecols=['Id', 'Body']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "906ef06f075087ed5e55c7389674412ba763fee8"
   },
   "outputs": [],
   "source": [
    "# print('>>> Q:', qdf.iloc[0, 2], \"\\n\")\n",
    "# print('>>> A:', adf.iloc[0, 1], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "97b48209e063f56a31206be254614ed4c573e790"
   },
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2bebded00eb88856ae289d8e27baa81e7a6801f2"
   },
   "outputs": [],
   "source": [
    "def beautify(html_text):\n",
    "    soup = BeautifulSoup(html_text, 'lxml')\n",
    "    return ' '.join([t.text for t in soup.find_all('p')]) # concat all p tags\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(simple_preprocess(str(sentence), deacc=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "607282\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c462ad2ebc36477a918f32e9d619df56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=607282), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590d4e982cc74624b390918613c86c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=607282), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "26592971\n"
     ]
    }
   ],
   "source": [
    "### DUMP\n",
    "# question_list = qdf['Body'].progress_apply(beautify).values.tolist()\n",
    "# question_words = [list(filter(lambda w : w not in stop_words, s)) for s in sent_to_words(question_list)]\n",
    "# pickle.dump(question_words, open(os.path.join(base_dir, 'question_words_clean.pickle'), 'wb'))\n",
    "\n",
    "### LOAD\n",
    "question_words = pickle.load(open(os.path.join(base_dir, 'question_words_clean.pickle'), 'rb'))\n",
    "print(len(question_words))\n",
    "\n",
    "q_vocab = Counter()\n",
    "for s in tqdm(question_words):\n",
    "    for w in s:\n",
    "        q_vocab[w] += 1\n",
    "        \n",
    "x = []\n",
    "for s in tqdm(question_words):\n",
    "    for w in s:\n",
    "        if q_vocab[w] >= 100:\n",
    "            x += [w]\n",
    "print(len(x))\n",
    "\n",
    "# ---\n",
    "\n",
    "# answer_list = adf['Body'].progress_apply(beautify).values.tolist()\n",
    "# answer_words   = [list(filter(lambda w : w not in stop_words, s)) for s in sent_to_words(answer_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "50b88ec3796927e67ae59671bc13cc28396052ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'function', 'execute', 'parameter', 'return', 'extract', 'pass', 'sort', 'method', 'functions', 'assign', 'call', 'variable', 'invoke', 'arguments', 'methods', 'argument', 'change', 'parameters'}\n"
     ]
    }
   ],
   "source": [
    "needed = [\n",
    "    'call', 'function', 'arguments', 'parameter', 'method', 'invoke', 'assign', 'return',\n",
    "    'variable', 'functions', 'argument', 'parameters', 'methods', 'execute', 'pass',\n",
    "    'change', 'extract', 'sort'\n",
    "]\n",
    "\n",
    "topw = [w for w, x in q_vocab.most_common() if ]\n",
    "\n",
    "print(set(needed) - set(topw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c19d7852f9e84e157d2903774ee4aad9f8c8b99c"
   },
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "e2283facaf0ef42a0d13d625415f0ff264e9bfbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241142968, 278505320)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 50\n",
    "model = Word2Vec(question_words, size=n, window=8, min_count=100)\n",
    "\n",
    "model.train(question_words, total_examples=len(question_words), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "ecfe822d97fc72b0d457516ab2a05c4c132fb63a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 9736\n",
      "\n",
      "\n",
      "> similar to 'python':\n",
      "[('pyhton', 0.7207606434822083),\n",
      " ('lua', 0.645491361618042),\n",
      " ('ironpython', 0.6337897777557373),\n",
      " ('jython', 0.6129292249679565),\n",
      " ('standalone', 0.5896718502044678),\n",
      " ('java', 0.5873558521270752),\n",
      " ('scripting', 0.5789278149604797),\n",
      " ('library', 0.5697588920593262),\n",
      " ('perl', 0.5666365027427673),\n",
      " ('cygwin', 0.5611815452575684),\n",
      " ('iron', 0.5604820251464844),\n",
      " ('pythons', 0.5481476783752441),\n",
      " ('sage', 0.5451010465621948),\n",
      " ('swift', 0.5423818230628967),\n",
      " ('gem', 0.5403555035591125),\n",
      " ('comtypes', 0.5399928092956543),\n",
      " ('powershell', 0.5346354842185974),\n",
      " ('ruby', 0.5337449312210083),\n",
      " ('nodejs', 0.5331274271011353),\n",
      " ('julia', 0.5294690132141113)]\n"
     ]
    }
   ],
   "source": [
    "print(\"vocab size: %d\\n\\n\" % len(model.wv.vocab))\n",
    "\n",
    "word = 'python'\n",
    "print(\"> similar to '%s':\" % word)\n",
    "pprint(model.wv.most_similar(positive=word, topn=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0f9ddd705b519dd5d133e2aca7dfae396d423600"
   },
   "source": [
    "## FastText\n",
    "The main difference of FastText from Word2Vec is that it uses sub-word information (i.e character n-grams). While it brings additional utility to the embeddings, it also considerably slows down the process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7980a123b38e246191dc18ea827d2ed3d7f1d0e7"
   },
   "outputs": [],
   "source": [
    "ft_model = FastText(question_words, size=n, window=8, min_count=5, workers=2,sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c0333451b4c1514cb1e47a3b61b2f6f812e815a2"
   },
   "outputs": [],
   "source": [
    "word = 'call'\n",
    "print(\"> similar to '%s':\" % word)\n",
    "pprint(ft_model.wv.most_similar(positive=word, topn=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b602b437ab44f90bc2a3d47fedaf38ceccf9d846"
   },
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "98efa9676b2515445cb5ee2b98be26a75d4f187e"
   },
   "outputs": [],
   "source": [
    "#dct = Dictionary(filtered_questions)  # fit dictionary\n",
    "#corpus = [dct.doc2bow(line) for line in filtered_questions]  # convert corpus to BoW format\n",
    "#tfidf_model = TfidfModel(corpus)  # fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6ad852e394420e1e98b13d9c76085e8d2e3b1a3f"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(question_list)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a4c41a3fa84f3b024dd4b9d4719ae7899ffa972"
   },
   "outputs": [],
   "source": [
    "#To proprely work with scikit's vectorizer\n",
    "merged_questions = [' '.join(question) for question in filtered_questions]\n",
    "document_names = ['Doc {:d}'.format(i) for i in range(len(merged_questions))]\n",
    "\n",
    "def get_tfidf(docs, ngram_range=(1,1), index=None):\n",
    "    vect = TfidfVectorizer(stop_words='english', ngram_range=ngram_range)\n",
    "    tfidf = vect.fit_transform(docs).todense()\n",
    "    return pd.DataFrame(tfidf, columns=vect.get_feature_names(), index=index).T\n",
    "\n",
    "tfidf = get_tfidf(merged_questions, ngram_range=(1,1), index=document_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "14b952dec5bfbd3ac21bfc960d3e705f3cfdbc6a"
   },
   "source": [
    "### Centroid Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd01992d62b205fa749cefe55552a153792c7cfc"
   },
   "outputs": [],
   "source": [
    "def get_sent_embs(emb_model):\n",
    "    sent_embs = []\n",
    "    for desc in range(len(filtered_questions)):\n",
    "        sent_emb = np.zeros((1, n))\n",
    "        if len(filtered_questions[desc]) > 0:\n",
    "            sent_emb = np.zeros((1, n))\n",
    "            div = 0\n",
    "            model = emb_model\n",
    "            for word in filtered_questions[desc]:\n",
    "                if word in model.wv.vocab and word in tfidf.index:\n",
    "                    word_emb = model.wv[word]\n",
    "                    weight = tfidf.loc[word, 'Doc {:d}'.format(desc)]\n",
    "                    sent_emb = np.add(sent_emb, word_emb * weight)\n",
    "                    div += weight\n",
    "                else:\n",
    "                    div += 1e-13 #to avoid dividing by 0\n",
    "        if div == 0:\n",
    "            print(desc)\n",
    "\n",
    "        sent_emb = np.divide(sent_emb, div)\n",
    "        sent_embs.append(sent_emb.flatten())\n",
    "    return sent_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f2526b714ebd3e7d57bf1fd3801b166a5c5184a"
   },
   "outputs": [],
   "source": [
    "ft_sent = get_sent_embs(emb_model = ft_model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1617fc5085def2c1241b4d3b127e9af3789f80f6"
   },
   "source": [
    "## Finding Similar Questions\n",
    "Now we have sentence embeddings which in theory should reflect the similarity of some questions. To check if this assumption is valid, let's pick a question and find top 5 similar questions (knearest neighbours) as measured by cosine distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "66696ffbc347158a145eaa9c3c80fe3e1352b7f6"
   },
   "outputs": [],
   "source": [
    "def get_n_most_similar(interest_index, embeddings, n):\n",
    "    \"\"\"\n",
    "    Takes the embedding vector of interest, the list with all embeddings, and the number of similar questions to \n",
    "    retrieve.\n",
    "    Outputs the disctionary IDs and distances\n",
    "    \"\"\"\n",
    "    nbrs = NearestNeighbors(n_neighbors=n, metric='cosine').fit(embeddings)\n",
    "    distances, indices = nbrs.kneighbors(embeddings)\n",
    "    similar_indices = indices[interest_index][1:]\n",
    "    similar_distances = distances[interest_index][1:]\n",
    "    return similar_indices, similar_distances\n",
    "\n",
    "def print_similar(interest_index, embeddings, n):\n",
    "    \"\"\"\n",
    "    Convenience function for visual analysis\n",
    "    \"\"\"\n",
    "    closest_ind, closest_dist = get_n_most_similar(interest_index, embeddings, n)\n",
    "    print('Question %s \\n \\n is most similar to these %s questions: \\n' % (question_list[interest_index], n))\n",
    "    for question in closest_ind:\n",
    "        print('ID ', question, ': ',question_list[question])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2d7afc4ef1fd1b359f8356479a330bee0b70e7cc"
   },
   "outputs": [],
   "source": [
    "print_similar(42, ft_sent, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b123d1321f18f30c5e201c92c7fb7f8a12dbfb39"
   },
   "source": [
    "Results are quite interesting. All of the questions are about some kind of text processing. Not exactly repeating questions, but we are definitely onto something. Possible explanation for a weak perfromance is that questions are too long and the final embedding is influenced by too much noise. My hope was that tf-idf score would counteract this, but apparently this is not the case. However, for shorter texts, this method works quite well. \n",
    "\n",
    "Next appraoch will be a more complicated (in terms of theory, not implementation) model called __Doc2Vec__. \n",
    "\n",
    "## Doc2Vec\n",
    "Doc2Vec improves on simple averaging method by training a 'document' vector along the word vectors. As in Word2Vec there are two algortihms available to train the model, but I will be using the 'distributed memory' (that's why dm=1 in my model). It trains a model which predicts a word based on its context, by averaging the context word and paragraph ID vectors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8cf50b70016380b5dfff7b99f25e7f8a7466606a"
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(filtered_questions)]\n",
    "model = Doc2Vec(documents, vector_size=n, window=8, min_count=5, workers=2, dm = 1, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e3dd01d7332bae20c128734ebb03a2426e9d27da"
   },
   "outputs": [],
   "source": [
    "print(question_list[42], ' \\nis similar to \\n')\n",
    "print([question_list[similar[0]] for similar in model.docvecs.most_similar(42)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f892b54e7a6da6f549b007c9f340ecff6beab4f6"
   },
   "source": [
    "Results are less than impressive. Some results are about string manipulations or SQL, but Doc2Vec has failed to capture the main meaning of the reference question. \n",
    "\n",
    "From the current analysis I can conclude that with current parameters, __Centroid Method outperforms Doc2Vec__. Here's is another example of similar questions being close to each-other under the Centroid Method Embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "14c526ac12171ae5c11bdd7d3fefcc938ac99864"
   },
   "outputs": [],
   "source": [
    "print_similar(101, ft_sent, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe8915eacb9e8da39d6efa9d41620d3d5f76e823"
   },
   "source": [
    "Next steps to improve embeddings would be to:\n",
    "* Add more tags to Doc2Vec which, in theory, would push questions with similar tags closer together\n",
    "* Concatenate question headers and code parts with question text \n",
    "* Experiment with more questions (now we are training on a limited dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
