{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAPS Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "from pprint import pprint\n",
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_root = '../../raw-datasets/naps'\n",
    "train_file_A = _root + '/naps.trainA.1.0.jsonl' # 5.9G\n",
    "train_file_B = _root + '/naps.trainB.1.0.jsonl'\n",
    "test_file    = _root + '/naps.test.1.0.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_by_key(example, key):\n",
    "    if isinstance(example[key], str):\n",
    "        ch = \" \" if key in ['text', 'code_sequence'] else \"\"\n",
    "        return ch.join(example[key])\n",
    "    else:\n",
    "        return example[key]\n",
    "\n",
    "def get_all_by_key(data, key):\n",
    "    return [get_by_key(d, key) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [dict(json.loads(l)) for l in [l.strip() for l in open(train_file_B, \"rt\").readlines()]]\n",
    "test_data  = [dict(json.loads(l)) for l in [l.strip() for l in open(test_file, \"rt\").readlines()]]\n",
    "\n",
    "keys = list(train_data[0].keys())\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0, len(train_data))\n",
    "all_texts = [' '.join(get_by_key(train_data[i], key='text')) for i in range(len(train_data))]\n",
    "\n",
    "print(idx)\n",
    "all_texts[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(vocab, xs):\n",
    "    for x in xs:\n",
    "        vocab[x] += 1\n",
    "    return vocab\n",
    "\n",
    "def clean(word):\n",
    "    word = word.lower()\n",
    "    b1 = re.match(r'[^a-z]$', word)\n",
    "    b2 = re.match(r'^var[0-9]+', word)\n",
    "    b3 = word in STOP_WORDS\n",
    "    return b1 is None and b2 is None and not b3\n",
    "\n",
    "vocabulary = Counter()\n",
    "for i in range(len(train_data)):\n",
    "    vocabulary = update(\n",
    "        vocabulary, \n",
    "        xs=list(map(lambda w : w, filter(clean, get_by_key(train_data[i], key='text'))))\n",
    "    )\n",
    "\n",
    "print(f\"vocab length: {len(vocabulary)}\")\n",
    "    \n",
    "pred = lambda x : x > 50\n",
    "labels, values = zip(*filter(lambda p : pred(p[1]), vocabulary.most_common()))\n",
    "\n",
    "plt.figure(figsize=(int(0.41 * len(values)), 6))\n",
    "plt.xticks(range(len(values)), labels, rotation=70, fontsize=10)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.yscale('log')\n",
    "plt.plot(range(len(values)), values, 'b-')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
