{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import torch\n",
    "import torchtext\n",
    "import os\n",
    "import random\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, '../preprocess/')\n",
    "sys.path.insert(0, '../../coarse2fine.git/src')\n",
    "\n",
    "from sketch_generation import Sketch\n",
    "from tree import SketchRepresentation\n",
    "import table\n",
    "import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_WORD = '<unk>'\n",
    "UNK = 0\n",
    "PAD_WORD = '<blank>'\n",
    "PAD = 1\n",
    "BOS_WORD = '<s>'\n",
    "BOS = 2\n",
    "EOS_WORD = '</s>'\n",
    "EOS = 3\n",
    "SKP_WORD = '<sk>'\n",
    "SKP = 4\n",
    "RIG_WORD = '<]>'\n",
    "RIG = 5\n",
    "LFT_WORD = '<[>'\n",
    "LFT = 6\n",
    "SPECIAL_TOKEN_LIST = [UNK_WORD, PAD_WORD, BOS_WORD, EOS_WORD, SKP_WORD, RIG_WORD, LFT_WORD]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore TableDataset fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_field(data, field):\n",
    "    print(field)\n",
    "    try:\n",
    "        print(\" \".join(getattr(data, field)))\n",
    "    except:\n",
    "        print(\"N/A\")\n",
    "    print(\"-\"*64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = conala\n",
    "\n",
    "file = '../../coarse2fine.git/data_model/%s/train.pt' % dataset\n",
    "fields = sorted(list(table.IO.TableDataset.get_fields().keys()))\n",
    "\n",
    "data = torch.load(file)\n",
    "data.fields = table.IO.TableDataset.get_fields()\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(data.examples))\n",
    "\n",
    "# for f in fields:\n",
    "#     print_field(data.examples[i], f)\n",
    "\n",
    "ex = [data.examples[i] for i in range(len(data.examples)) if any(['FUNC#%d' % j in data.examples[i].lay for j in range(10)])]\n",
    "i = random.randint(0, len(ex))\n",
    "\n",
    "print(i)\n",
    "print_field(ex[i], 'src')\n",
    "print_field(ex[i], 'tgt_loss')\n",
    "print_field(ex[i], 'lay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Their sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../../coarse2fine.git/data_model/%s/train.json' % dataset\n",
    "df = pd.read_json(file, lines=True)\n",
    "df = [df.iloc[i] for i in range(len(df)) if True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(df))\n",
    "# i = 4654\n",
    "\n",
    "print(i)\n",
    "print(\"src     \", df[i]['src'])\n",
    "print(\"token   \", df[i]['token'])\n",
    "\n",
    "t = tree.SketchRepresentation((df[i]['token'], df[i]['type']))\n",
    "\n",
    "lay = t.layout(add_skip=False)\n",
    "lay_skip = t.layout(add_skip=True)\n",
    "tgt = t.target()\n",
    "\n",
    "print(\"lay     \", lay)\n",
    "print(\"lay_skip\", lay_skip)\n",
    "print(\"tgt     \", tgt)\n",
    "\n",
    "print(\"\\n\", \"-\"*64, \"\\n\")\n",
    "\n",
    "r_list = []\n",
    "src_set = set(df[i]['src'])\n",
    "\n",
    "for tk_tgt in t.target():\n",
    "    if tk_tgt in src_set:\n",
    "        print(\"ok\\t\", tk_tgt)\n",
    "        r_list.append(tk_tgt)\n",
    "    else:\n",
    "        print(\"unk\\t\", tk_tgt)\n",
    "        r_list.append(UNK_WORD)\n",
    "        \n",
    "cttgt = table.IO.TableDataset._read_annotated_file(None,None,df, 'copy_to_tgt', None)\n",
    "src= table.IO.TableDataset._read_annotated_file(None,None,df, 'src', None)\n",
    "list(cttgt) == list(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "\n",
    "src_field = torchtext.data.Field(pad_token=PAD_WORD, include_lengths=True)\n",
    "\n",
    "counter = Counter()\n",
    "sources = [getattr(data, 'src')]\n",
    "\n",
    "for data in sources:\n",
    "    for x in data:\n",
    "        counter.update(x)\n",
    "\n",
    "counter.most_common(20)\n",
    "# print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_index(tk_list):\n",
    "    stack = [0]\n",
    "    r_list = []\n",
    "    \n",
    "    for i, tk in enumerate(tk_list):\n",
    "        print(i, tk)\n",
    "        r_list.append(stack[-1])\n",
    "        \n",
    "        if tk.startswith('('):\n",
    "            # +1: because the parent of the top level is 0\n",
    "            stack.append(i + 1)\n",
    "        elif tk == ')':\n",
    "            stack.pop()\n",
    "            \n",
    "    # for EOS (</s>)\n",
    "    r_list.append(0)\n",
    "    return r_list\n",
    "\n",
    "\n",
    "# get_parent_index('x = func ( a + func2 ( x + y ) )'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lay_index(lay_skip):\n",
    "    # with a <s> token at the first position\n",
    "    r_list = [0]\n",
    "    k = 0\n",
    "    for tk in lay_skip:\n",
    "        if tk in (SKP_WORD, RIG_WORD):\n",
    "            r_list.append(0)\n",
    "        else:\n",
    "            r_list.append(k)\n",
    "            k += 1\n",
    "    return r_list\n",
    "\n",
    "get_lay_index('NAME = FUNC#1 ( NAME )'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../../coarse2fine.git/data_model/%s/vocab.pt' % dataset\n",
    "fields = table.IO.TableDataset.load_fields(torch.load(file))\n",
    "\n",
    "len(sorted(list(fields['tgt'].vocab.stoi.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load('../../coarse2fine.git/data_model/%s/train.pt' % dataset)\n",
    "fields = table.IO.TableDataset.load_fields(torch.load('../../coarse2fine.git/data_model/%s/vocab.pt' % dataset))\n",
    "train_data.fields = dict([(k, f) for (k, f) in fields.items() if k in train_data.examples[0].__dict__])\n",
    "train_iter = table.IO.OrderedIterator(train_data, 1, device=-1, repeat=False)\n",
    "\n",
    "fields = train_data.fields\n",
    "_i = random.randint(0, len(train_data))\n",
    "\n",
    "for i, batch in enumerate(train_iter):\n",
    "    if i == _i: break\n",
    "        \n",
    "print(batch.indices)\n",
    "        \n",
    "print('> src')\n",
    "for i in batch.src[0].data:\n",
    "    print(fields['src'].vocab.itos[i[0]], end=\" \")\n",
    "print('\\n')\n",
    "\n",
    "print('> lay')\n",
    "for i in batch.lay[0].data:\n",
    "    print(fields['lay'].vocab.itos[i[0]], end=\" \")\n",
    "print('\\n')\n",
    "\n",
    "# print(batch.copy_to_ext)\n",
    "\n",
    "attr = sorted([x for x in dir(batch) if x[:2] != '__' and x not in ['src', 'lay']])\n",
    "\n",
    "for a in attr:\n",
    "    print('>', a)\n",
    "    if hasattr(getattr(batch, a), 'data') and a in fields.keys() and hasattr(fields[a], 'vocab'):\n",
    "        for i in getattr(batch, a).data:\n",
    "            print(fields[a].vocab.itos[i[0]], end=\" \")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SURE FUNC# APPEARS ONLY IN LAY VOCABS\n",
    "for a in attr:\n",
    "    if a in fields.keys() and hasattr(fields[a], 'vocab'):\n",
    "        x = fields[a].vocab.stoi.keys()\n",
    "        print(a)\n",
    "        for i in range(10):\n",
    "            if a in ['lay', 'lay_e']:\n",
    "                assert 'FUNC#%d' % i in x, str(i)\n",
    "            else:\n",
    "                assert 'FUNC#%d' % i not in x, str(i)\n",
    "                \n",
    "# pred   <s> t1 t2 t2 t5 </s>\n",
    "# target <s> t1 t2 t3 t4 </s>\n",
    "# mask    1   0  0  0  0  1\n",
    "# p=t     1   1  1  0  0  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.ByteTensor([1,0,0,0,0,0,1])\n",
    "pred =     torch.Tensor([0,1,2,3,3,4,4])\n",
    "goal =     torch.Tensor([0,1,1,2,3,4,5])\n",
    "\n",
    "x = pred.eq(goal).masked_select(mask.ne(1))\n",
    "y = mask.ne(1).sum()\n",
    "\n",
    "print(x)\n",
    "# 1 1 1 0 1 1 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
